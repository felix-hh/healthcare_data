{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4d5a07-c95c-4b6f-a192-8bca805899e2",
   "metadata": {},
   "source": [
    "### Hospital Metadata Creation\n",
    "\n",
    "Why do we create metadata? Separating the metadata from the parsing steps allows us to improve on each one independently. The metadata from this process allows us to parse directly on the files. \n",
    "\n",
    "The goal of the config process is to identify the hospitals that have valid input data and prepare the files for extraction. There are 2 failure modes at this stage: 1) the hospital does not have a valid csv or excel file with all CDM data and 2) the hospital does not have the necessary columns i.e. excludes CPT Code. Inability to parse is not a failure mode at this stage. \n",
    "\n",
    "Note: I do not use the classes above, except maybe a HospitalData class. As of now raw dictionaries feel better. I will structure the data in a dictioinary of hospital names mapping to objects, and dump it in a json file. \n",
    "\n",
    "We approach the creation of the metadata above in the following steps:\n",
    "- Folder name extraction: match hospital names to a year and a valid folder where it's data is located.\n",
    "- Sheet extraction: of the available valid files, find the file and sheet which contains the necessary data. Use keywords and sane defaults to automate as possible, and rely on human input to break ties. \n",
    "- Column extraction: on the files obtained on the previous step, find the valid columns index containing the data. Come up with keywords and sane defaults, and rely on human input showing 20 rows of the dataframe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f19a96c-e5c5-42e1-81f9-9ad105667120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mental model\n",
    "\n",
    "class SheetDefinition:\n",
    "    hasValidSheets: bool # for my purposes, it means that allData is defined and unique\n",
    "    allData: [str, str] # file, filesheet\n",
    "    # common25: [str, str]\n",
    "    # rxData: [str, str]\n",
    "    \n",
    "class ColumnDefinition:\n",
    "    hasValidColumns: bool\n",
    "    cpt: int\n",
    "    avgCharge: int\n",
    "    procedureName: int\n",
    "    \n",
    "class HospitalData: \n",
    "    hospitalName: str\n",
    "    year: int\n",
    "    folderPath: str # actually a path object\n",
    "    \n",
    "    sheets: SheetDefinition\n",
    "    columns: bool\n",
    "\n",
    "class HospitalsData(dict):\n",
    "    def addData(name: str, data: HospitalData):\n",
    "        this['name'] = data\n",
    "    \n",
    "# example\n",
    "sampleData = \\\n",
    "{\n",
    "    \"myHospital\": {\n",
    "        \"hospitalName\": \"myHospital\",\n",
    "        \"oshpdId\": 123456789,\n",
    "        \"year\": 2021,\n",
    "        \"folderPath\": \"myHospitalPath\",\n",
    "        \"hasValidPaths\": True,\n",
    "        \"hasValidSheets\": True,\n",
    "        \"sheets\": {\n",
    "            \"allData\": {\n",
    "                \"file\": \"myFile\",\n",
    "                \"sheet\": \"mySheet\"\n",
    "            }\n",
    "        },\n",
    "        \"hasValidColumns\": True,\n",
    "        \"columns\": {\n",
    "            \"cpt\": 0,\n",
    "            \"avgCharge\": 3,\n",
    "            \"procedureName\": 1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73783ef-7a7a-4fee-8f2c-cb3b8d9f43d2",
   "metadata": {},
   "source": [
    "### Get directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdffc160-f844-4718-bda5-986bbf754af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "warnings.filterwarnings('ignore', category=SettingWithCopyWarning, module='pandas')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "YEAR = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ace4f2e-380d-40a3-9821-440b43521993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AHMC Anaheim Regional Medical Center',\n",
      "  {'dirPath': PosixPath('../chargemaster-cdm-2021/AHMC Anaheim Regional Medical Center'),\n",
      "   'hospitalName': 'AHMC Anaheim Regional Medical Center',\n",
      "   'year': 2021}),\n",
      " ('AHMC Seton Medical Center',\n",
      "  {'dirPath': PosixPath('../chargemaster-cdm-2021/AHMC Seton Medical Center'),\n",
      "   'hospitalName': 'AHMC Seton Medical Center',\n",
      "   'year': 2021}),\n",
      " ('Alameda Hospital',\n",
      "  {'dirPath': PosixPath('../chargemaster-cdm-2021/Alameda Hospital'),\n",
      "   'hospitalName': 'Alameda Hospital',\n",
      "   'year': 2021}),\n",
      " ('Alhambra Hospital Medical Center',\n",
      "  {'dirPath': PosixPath('../chargemaster-cdm-2021/Alhambra Hospital Medical Center'),\n",
      "   'hospitalName': 'Alhambra Hospital Medical Center',\n",
      "   'year': 2021}),\n",
      " ('Alta Bates Summit Medical Center',\n",
      "  {'dirPath': PosixPath('../chargemaster-cdm-2021/Alta Bates Summit Medical Center'),\n",
      "   'hospitalName': 'Alta Bates Summit Medical Center',\n",
      "   'year': 2021})]\n"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "\n",
    "dataPath = Path(\"../chargemaster-cdm-2021\")\n",
    "processingPath = Path('.') / 'processing'\n",
    "\n",
    "def extractDirectoryMetadata(dataPath):\n",
    "    folders = sorted(list(dataPath.iterdir()))\n",
    "\n",
    "    for folder in folders:\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "\n",
    "        metadata[folder.name] = {\n",
    "            \"hospitalName\": folder.name,\n",
    "            \"year\": YEAR,\n",
    "            \"dirPath\": folder\n",
    "        }\n",
    "        \n",
    "extractDirectoryMetadata(dataPath)\n",
    "pprint(list(metadata.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b9aa2-3534-428d-8db1-1ea58bb48835",
   "metadata": {},
   "source": [
    "### Get file paths for allData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d685d-f592-4169-bd05-8f5e7d138908",
   "metadata": {},
   "source": [
    "How have I dealt with folders that contain multiple hospital data?\n",
    "I have manually separated them into separate folders, looking up the name of the unidentified hospitals by looking up facility data using the OSHPD Id. \n",
    "\n",
    "How have I dealt with folders that only have invalid data?\n",
    "Only one instance contained the data dispersed on multiple files without cpt codes. For that, I deleted that instance. In the future I would rather skip it with a comment. \n",
    "\n",
    "How have I dealt with undistinguishable non CDM files?\n",
    "Renamed '106370782_CDM(2)_2021.xlsx' to a name not containing CDM or All. The file contained data about supplies that was not relevant enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69fd7b9-0ac3-42ae-9efb-670e8fc8bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notes\n",
    "# lookout for false positives, skip file if rx is present\n",
    "# skip .db files, skip ~ files\n",
    "# beware of multiple matching files\n",
    "# one file per hospital, for now. We will support multiple ids and files later. \n",
    "# obtain OSHPD Facility No. from filename Note: some hospitals have multiple facilities => diff numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959f6f97-8414-4f60-a2cb-2754885178bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 321/321 [00:00<00:00, 5072.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with Joyce Eisenberg Keefer Medical Center: Files not found by default\n",
      "The candidates are:\n",
      "['106196404_CDM(1)_2021.xlsx',\n",
      " '106196404_CDM(2)_2021.xlsx',\n",
      " '106196404_CDM(3)_2021.xlsx',\n",
      " '106196404_CDM(4)_2021.xlsx']\n",
      "Select index (1-indexed) or input 's' to skip with a note\n",
      "More than 1 file present for 1 facility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extractFilepathMetadata(metadata):\n",
    "    #file detection regex\n",
    "    ALL_DATA_REGEX = re.compile(r\"^(\\d*).*(all|cdm).*(\\.xls[xm]?|csv)$\", re.MULTILINE | re.IGNORECASE)\n",
    "    RX_DATA_REGEX = re.compile(r\"^(\\d*).*(rx).*(\\.xls[xm]?|csv)$\", re.MULTILINE | re.IGNORECASE)\n",
    "    COMMON_25_DATA_REGEX = re.compile(r\"^(\\d*).*(\\D25|common).*(\\.xls[xm]?|csv)$\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    for hospital, hospital_data in tqdm(sorted(list(metadata.items()))):    \n",
    "        # find good allData files\n",
    "        filePaths = sorted(list(hospital_data[\"dirPath\"].iterdir()))\n",
    "        filePaths = [path for path in filePaths if not path.name.startswith('~') and not path.suffix=='.db']\n",
    "        filePaths = [path for path in filePaths if not RX_DATA_REGEX.match(path.name)]\n",
    "        filePaths = [path for path in filePaths if ALL_DATA_REGEX.match(path.name)]\n",
    "\n",
    "        # If there are no files, note to user and continue\n",
    "        if len(filePaths) == 0:\n",
    "            note = \"This hospital has no candidate files\"\n",
    "            print(note)\n",
    "            metadata[hospital][\"hasValidPaths\"]=False\n",
    "            metadata[hospital][\"error\"]=note\n",
    "            continue\n",
    "\n",
    "        # If there is only 1 possible file, assume it is good and proceed\n",
    "        elif len(filePaths) == 1:\n",
    "            # This is the happy scenario. You can manually edit the data until \n",
    "            # all files execute this branch, as a short term measure\n",
    "\n",
    "            hospitalId = ALL_DATA_REGEX.match(filePaths[0].name).groups()[0]\n",
    "            metadata[hospital][\"hasValidPaths\"]=True\n",
    "            metadata[hospital][\"oshpdId\"]= hospitalId\n",
    "            metadata[hospital][\"filepath\"]= filePaths[0]\n",
    "\n",
    "        else:\n",
    "            print(f\"Problem with {hospital}: Files not found by default\")\n",
    "            print(\"The candidates are:\")\n",
    "            pprint([path.name for path in filePaths])\n",
    "            print(\"Select index (1-indexed) or input 's' to skip with a note\")\n",
    "            # userInput = input()\n",
    "            userInput = 's'\n",
    "            if userInput == 's':\n",
    "                note = \"More than 1 file present for 1 facility\"\n",
    "                print(note)\n",
    "                metadata[hospital][\"hasValidPaths\"]=False\n",
    "                metadata[hospital][\"error\"]=note\n",
    "                continue\n",
    "\n",
    "            suggestedIdx = int(userInput)-1\n",
    "            hospitalId = ALL_DATA_REGEX.match(filePaths[suggestedIdx].name).groups()[0]        \n",
    "            print(f\"Selected hospital {filePaths[suggestedIdx].name} with id {hospitalId}\")\n",
    "            metadata[hospital][\"hasValidPaths\"]=True\n",
    "            metadata[hospital][\"oshpdId\"]= hospitalId\n",
    "            metadata[hospital][\"filepath\"]= filePaths[suggestedIdx]\n",
    "\n",
    "extractFilepathMetadata(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299a2da1-f393-4083-a1e5-af3c36cf6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: 320, failed to parse: 1\n"
     ]
    }
   ],
   "source": [
    "failedCount = len([data for data in list(metadata.values())if not data[\"hasValidPaths\"]])\n",
    "successCount = len([data for data in list(metadata.values())if data[\"hasValidPaths\"]])\n",
    "print(f\"Parsed: {successCount}, failed to parse: {failedCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b5afa-ca97-4dae-88f6-b36e15ef02ef",
   "metadata": {},
   "source": [
    "### Get sheet names for allData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e440796-6502-49b8-9dca-17cc0db22ae7",
   "metadata": {},
   "source": [
    "**List of manual changes:**\n",
    "- Select all rows and clear all data format for Community Regional Medical Center - Fresno and Clovis Community Medical Center. This is to prevent an error parsing the excel file. \n",
    "- UCSD Medical Center: renamed sheet from CMS rates jan 21 to CMS rates jan 21 (felix rx). This classifies that sheet as rx which helps me parse. \n",
    "- Fresno Surgical Hospital: renamed chg master to ChargeMaster\n",
    "- Kindred Hospital Ontario: delete 2019 chargemaster\n",
    "- Modoc Medical Center: delete inactive chargemaster\n",
    "- Childrens Hospital at Orange County and Chiildrens Hospital at Mission: Renamed Revenue Usage sheet to CDM\n",
    "- Community Regional Medical Center Fresno: rename sheet from 2021 CDM HH to 2021 CDM HH (felix home)\n",
    "- Dameron Hospital: rename sheet Detail 2020-2021 to Detail 2020-2021 (felix change)\n",
    "- Keck Hospital: rename sheet Keck Hospital ChgMstr to Keck Hospital ChargeMstr\n",
    "- USC Norris Cancer Hospital: rename sheet USC Norris Cancer ChgMstr to USC Norris Cancer ChargeMstr\n",
    "\n",
    "**Not machine readable**\n",
    "- Good Samaritan Hospital - Bakersfield\n",
    "\n",
    "**No Valid Columns**\n",
    "- TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a361629-3a01-4b44-95a5-2f0eda41fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNonAllDataSheetNames(sheetNames):\n",
    "    # Sheet name regex\n",
    "    COMMON_PROCEDURES_REGEX = re.compile(r\"^.*(1045|AB).*$\") #don't ignore case!\n",
    "    COMMON_PROCEDURES_REGEX_2 = re.compile(r\"^.*(TOP| 50 |[Cc][Oo][Mm][Mm][oO][nN]).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    IRRELEVANT_SHEETS = re.compile(r\"^.*(%|PCT|CHANGE|PERCENTAGE|REV|REVENUE|DRUGS|SUPPLIES|SUPPLY|INCREASE|REMOVED).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    IRRELEVANT_SHEETS_2 = re.compile(r\"^.*(item.number|proccode|Round|levels|methodology|letter|summary|attestation|narrative|info|notes|board|home|disclosure).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    RX_SHEETS = re.compile(r\"^.*(PHARMACY|RX|Pharmaceutical).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    NON_FARMACY_CDM = re.compile(r\"^.*(Non-Pharmacy CDM).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    candidates = [sheet for sheet in sheetNames if \n",
    "                  not COMMON_PROCEDURES_REGEX.match(sheet) \n",
    "                  and not COMMON_PROCEDURES_REGEX_2.match(sheet)\n",
    "                 and not IRRELEVANT_SHEETS.match(sheet)            \n",
    "                 and not IRRELEVANT_SHEETS_2.match(sheet)            \n",
    "                and (not RX_SHEETS.match(sheet) or NON_FARMACY_CDM.match(sheet))\n",
    "                     ]\n",
    "    return candidates\n",
    "\n",
    "def greedyChooseAllDataSheetName(sheetNames):\n",
    "    # Sheetname Regex\n",
    "    GREEDY_CDM_1 = re.compile(r\"^.*(CDM).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    GREEDY_CDM_2 = re.compile(r\"^.*(master).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    # if an inpatient and an outpatient file is provided, we will read both. \n",
    "    # note the lack of .* since this is a very shallow pattern.\n",
    "    INPATIENT = re.compile(r\"^ip$\", re.MULTILINE | re.IGNORECASE)\n",
    "    OUTPATIENT = re.compile(r\"^op$\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    # Returns the greddy choice and a boolean indicating success in choosing. \n",
    "    sheetNames.sort()\n",
    "    for regex in [GREEDY_CDM_1, GREEDY_CDM_2]:\n",
    "        for sheet in sheetNames:\n",
    "            if regex.match(sheet):\n",
    "                return [sheet], True\n",
    "    if len(sheetNames) == 2:\n",
    "        if INPATIENT.match(sheetNames[0]) and OUTPATIENT.match(sheetNames[1]):\n",
    "            return sheetNames, True\n",
    "    return sheetNames, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdd2d2c-0137-4040-b054-c366e122bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveSheetToCsv(sheet: pd.DataFrame, fileTitle: str, dstPath: Path, safe=False)-> Path:\n",
    "    idx = 1\n",
    "    filename = f\"{fileTitle}.csv\"\n",
    "    newFilename = filename\n",
    "    if safe: \n",
    "        while dstPath.exists() and newFilename in dstPath.iterdir():\n",
    "            newFilename = f\"{filename}{idx:03}.csv\"\n",
    "    \n",
    "    resultFilepath = dstPath / newFilename  \n",
    "    dstPath.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    regex = r\"(\\s+)\"\n",
    "    subst = \" \"\n",
    "    headers = [(re.sub(regex, subst, str(header), 0, re.MULTILINE)).strip().lower()\n",
    "              for header in sheet.columns]\n",
    "               \n",
    "    sheet.to_csv(resultFilepath, header=headers)\n",
    "    return resultFilepath\n",
    "\n",
    "def addAllDataSheetToHospital(hospital, sheetName, sheet) -> None:\n",
    "    metadata[hospital][\"hasValidSheets\"] = True\n",
    "    if not \"sheets\" in metadata[hospital]:\n",
    "        metadata[hospital][\"sheets\"] = {}\n",
    "    metadata[hospital][\"sheets\"][sheetName] = {}\n",
    "    metadata[hospital][\"sheets\"][sheetName]['columnMappings'] = \\\n",
    "        {\n",
    "            \"cptCode\": None,\n",
    "            \"procedureName\": None,\n",
    "            \"avgCharge\": None\n",
    "        }\n",
    "    sheetCsvFile = saveSheetToCsv(sheet, sheetName, rawSheetCsvPath / hospital)\n",
    "    metadata[hospital][\"sheets\"][sheetName][\"sheetCsvFile\"] = sheetCsvFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00e9d39-3c16-403e-835d-e04d6a7c2102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▋                       | 138/321 [02:08<01:54,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital Kaweah Delta District Hospital has the following sheetNames:\n",
      "['Medical Center', 'Rural Health Clinics']\n",
      "Select 1-indexed index to keep that file, press 'a' to keep all, press 's' to skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [08:34<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "getMetadataFile = lambda x: x['filepath']\n",
    "rawSheetCsvPath = processingPath / 'raw-csv'\n",
    "failures = []\n",
    "allSheetNames = []\n",
    "\n",
    "\n",
    "for hospital, hospitalData in tqdm(sorted(list(metadata.items()))):\n",
    "    if not hospitalData[\"hasValidPaths\"]:\n",
    "        continue\n",
    "    time.sleep(0.1) #just so that the computer relaxes a bit. \n",
    "    filepath = getMetadataFile(hospitalData)\n",
    "    if filepath.suffix == '.csv':\n",
    "        addAllDataSheetToHospital(hospital, 'csv', pd.read_csv(filepath, index_col=0))\n",
    "        continue\n",
    "\n",
    "    # try:\n",
    "    excelFile = pd.ExcelFile(filepath)\n",
    "    sheetNames = excelFile.sheet_names\n",
    "    sheetNames = filterNonAllDataSheetNames(sheetNames)\n",
    "\n",
    "    if len(sheetNames) == 0:\n",
    "        raise Exception(\"Hospital has no available sheets after filtering\")\n",
    "\n",
    "    elif len(sheetNames) == 1:\n",
    "        sheetName = sheetNames[0]\n",
    "        addAllDataSheetToHospital(hospital, sheetName, excelFile.parse(sheetName, index_col=0))\n",
    "\n",
    "    else:\n",
    "        sheetNamesChoice, choiceSuccess = greedyChooseAllDataSheetName(sheetNames)\n",
    "        if choiceSuccess:\n",
    "            for sheetName in sheetNamesChoice:\n",
    "                addAllDataSheetToHospital(hospital, sheetName, excelFile.parse(sheetName, index_col=0))\n",
    "            continue\n",
    "\n",
    "        print(f\"Hospital {hospital} has the following sheetNames:\")\n",
    "        pprint(sheetNames)\n",
    "        print(\"Select 1-indexed index to keep that file, press 'a' to keep all, press 's' to skip\")\n",
    "        # userInput = input()\n",
    "        userInput = 'a' # keep all by default\n",
    "        if userInput == 'a':\n",
    "            for sheetName in sheetNames:\n",
    "                addAllDataSheetToHospital(hospital, sheetName, excelFile.parse(sheetName, index_col=0))\n",
    "        elif userInput == 's':\n",
    "            raise Exception(f\"Could not select a sheet among {sheetNames}\")\n",
    "        else:\n",
    "            selectedSheetIdx = int(userInput)-1\n",
    "            sheetName = sheetNames[selectedSheetIdx]\n",
    "            addAllDataSheetToHospital(hospital, sheetName, excelFile.parse(sheetName, index_col=0))\n",
    "                \n",
    "    # except Exception as e:\n",
    "    #     # traceback.print_exc()\n",
    "    #     # print(e)\n",
    "    #     # print(\"Failed to read sheet names\")\n",
    "    #     # print(\"Add a note on why this failed\")\n",
    "    #     # note = input()\n",
    "    #     print(f\"Failed at hospital: {hospital}\\nWith error:{e}\")\n",
    "    #     failures.append((hospital, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6caa8033-6b47-4eb6-9f61-3e1e5011dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid: Joyce Eisenberg Keefer Medical Center\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(320, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for hospital in metadata.keys():\n",
    "    if \"hasValidSheets\" in metadata[hospital] and metadata[hospital][\"hasValidSheets\"]:\n",
    "        counter+=1\n",
    "    else:\n",
    "        print(f\"Invalid: {hospital}\")\n",
    "counter, len(metadata.keys()) - counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65e3c1-4d11-4c73-994f-354ead0a63f4",
   "metadata": {},
   "source": [
    "### Finding the headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065303d3-0800-41f9-8ee7-05432aeb7a65",
   "metadata": {},
   "source": [
    "Finding the column mapping for cptCode, avgCharge and procedureName can be approached in multiple steps. \n",
    "\n",
    "1) Find the index_col of the file. Create a mapping for the right header in the metadata. Verify that the header contains all relevant fields to reduce work on step 2). \n",
    "2) Use the pd.index to transform the header onto a list, then process that list with regex and manual input to map the columns. \n",
    "\n",
    "We will catch most of the errors in step 1. \n",
    "- Category 1 errors: hospital data is not formatted properly i.e. does not contain CPT column.\n",
    "- Category 2 errors: we do not expect errors. \n",
    "\n",
    "Once we finish this, the data will be ready for parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0c81bb-2059-4724-9464-64e476603104",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:03, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad column format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [00:06, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital has 1 or fewer columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [00:26, 12.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#enable scrolling\n",
    "# from IPython.core.display import display, HTML\n",
    "# from IPython.display import clear_output\n",
    "# from collections import defaultdict\n",
    "# display(HTML(\"<style>.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea { max-height: 50em; max-width: 100em; }</style>\"))\n",
    "    \n",
    "def getSheetFilepath(hospital, sheet):\n",
    "    return metadata[hospital]['sheets'][sheet]['sheetCsvFile']\n",
    "    \n",
    "def dropMostlyNaColumns(df, definedValueThreshold= .05, inPlace=False):\n",
    "    if not inPlace:\n",
    "        df = df.copy()\n",
    "    nRows = len(df)\n",
    "\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        definedValues = sum(~df[col].isna())\n",
    "        definedRatio = definedValues / nRows\n",
    "        if definedRatio < definedValueThreshold:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def filepathToDataframe(filepath, sheetName=None, header=0):\n",
    "    sheet = None\n",
    "    if filepath.suffix == '.csv':\n",
    "        sheet = pd.read_csv(filepath, header=header)\n",
    "    else:\n",
    "        sheet = pd.read_excel(filepath, sheet_name=sheetName, header=header)\n",
    "    # sheet.index +=1\n",
    "    sheet = dropMostlyNaColumns(sheet)\n",
    "    regex = r\"(\\s+)\"\n",
    "    subst = \" \"\n",
    "    headers = [(re.sub(regex, subst, str(header), 0, re.MULTILINE)).strip().lower()\n",
    "              for header in sheet.columns]\n",
    "    sheet.set_axis(headers, axis=1, inplace=True)\n",
    "    sheet.set_index(sheet.columns[0], inplace=True)\n",
    "    return sheet\n",
    "\n",
    "\n",
    "def greedyHeaderChoice(sheet: pd.DataFrame)-> int:\n",
    "    UNTITLED_REGEX = re.compile(r\"^.*(untitled|Unnamed).*$\", re.MULTILINE | re.IGNORECASE)\n",
    "    headers = sheet.columns\n",
    "    isUntitled = any([UNTITLED_REGEX.match(header) for header in headers])\n",
    "    if not isUntitled:\n",
    "        return 0\n",
    "    else:\n",
    "        for idx, (_, row) in enumerate(sheet.iterrows()):\n",
    "            if idx > 50:\n",
    "                break\n",
    "            if not any(row.isna()):\n",
    "                return idx+1\n",
    "        return None\n",
    "\n",
    "def getHeaderIdxFromUser(hospital, sheetName, guessHeaderIdx = None, nToDisplay=4) -> int:\n",
    "    filepath = getSheetFilepath(hospital, sheetName)\n",
    "    if guessHeaderIdx == None:\n",
    "        sheet = filepathToDataframe(filepath, sheetName, 0)\n",
    "        guessHeaderIdx = greedyHeaderChoice(sheet)\n",
    "        if guessHeaderIdx == None:\n",
    "            raise Exception(\"Bad column format\")\n",
    "    # print(f\"Guessed index {guessHeaderIdx}\")\n",
    "    sheet = filepathToDataframe(filepath, sheetName, guessHeaderIdx)\n",
    "    \n",
    "    if len(sheet.columns) <=0:\n",
    "        raise Exception(\"Hospital has 1 or fewer columns\")\n",
    "        return\n",
    "    \n",
    "    # display(sheet.head(nToDisplay))\n",
    "    # userInput = input()\n",
    "    \n",
    "#     if userInput == 'q':\n",
    "#         print(\"Explain why this is invalid input:\")\n",
    "#         reason = input()\n",
    "#         raise Exception(reason)\n",
    "    \n",
    "#     if userInput == 'n':\n",
    "#         return getHeaderIdxFromUser(hospital, sheetName, 0, 15)\n",
    "    \n",
    "#     if userInput == '':\n",
    "#         userInput = 0\n",
    "#     userInput = int(userInput)\n",
    "    userInput = 0 #use auto\n",
    "    headerIdx = guessHeaderIdx+userInput\n",
    "    # print (f\"Saving header index for hospital as {headerIdx}\")\n",
    "    return headerIdx, sheet\n",
    "            \n",
    "trimmedCsvDir = processingPath / 'trimmed-csv'\n",
    "def extractColumnHeaders(metadata):\n",
    "    for idx, (hospital, hospitalData) in tqdm(enumerate(sorted(list(metadata.items())))):\n",
    "        # clear_output()\n",
    "        # print(hospital, idx)\n",
    "        if not hospitalData['hasValidPaths'] or not hospitalData['hasValidSheets']:\n",
    "            continue\n",
    "        \n",
    "        for sheetName, sheetData in hospitalData['sheets'].items():\n",
    "            metadata[hospital]['sheets'][sheetName]['headerIdx'] = None\n",
    "            metadata[hospital]['sheets'][sheetName]['hasValidHeaders'] = None\n",
    "            metadata[hospital]['sheets'][sheetName]['trimmedCsvPath'] = None\n",
    "            metadata[hospital]['error'] = None\n",
    "            \n",
    "            try:\n",
    "                headerIdx, trimmedSheet = getHeaderIdxFromUser(hospital, sheetName)\n",
    "                metadata[hospital]['sheets'][sheetName]['headerIdx'] = headerIdx\n",
    "                metadata[hospital]['sheets'][sheetName]['hasValidHeaders']=True\n",
    "\n",
    "                trimmedSheetPath = saveSheetToCsv(trimmedSheet, sheetName, trimmedCsvDir / hospital)\n",
    "                metadata[hospital]['sheets'][sheetName]['trimmedCsvPath'] = trimmedSheetPath\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # input()\n",
    "                metadata[hospital]['error'] = e\n",
    "                metadata[hospital]['sheets'][sheetName]['hasValidHeaders'] = False\n",
    "        \n",
    "\n",
    "                \n",
    "extractColumnHeaders(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cd38626-7246-42aa-8bde-23f17d692d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def savePickleSafe(data, filepath):\n",
    "    idx = 1\n",
    "    parentFolder = filepath.parent\n",
    "    safeFilepath = filepath\n",
    "    while safeFilepath in list(parentFolder.iterdir()):\n",
    "        safeFilepath = parentFolder / f'{filepath.name[:-len(filepath.suffix)]}{idx:03}{filepath.suffix}'\n",
    "        idx+=1\n",
    "    with open(safeFilepath, 'wb') as handle:\n",
    "        pickle.dump(data, handle)\n",
    "    return safeFilepath\n",
    "\n",
    "def readPickle(filepath):\n",
    "    data = None\n",
    "    with open(filepath, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e45c533-e041-414e-8114-165e9b8e62dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AHMC Anaheim Regional Medical Center',\n",
       "  {'hospitalName': 'AHMC Anaheim Regional Medical Center',\n",
       "   'year': 2021,\n",
       "   'dirPath': PosixPath('../chargemaster-cdm-2021/AHMC Anaheim Regional Medical Center'),\n",
       "   'hasValidPaths': True,\n",
       "   'oshpdId': '106301098',\n",
       "   'filepath': PosixPath('../chargemaster-cdm-2021/AHMC Anaheim Regional Medical Center/106301098_CDM_All_2021.xlsx'),\n",
       "   'hasValidSheets': True,\n",
       "   'sheets': {'Price Transparency CDM': {'columnMappings': {'cptCode': None,\n",
       "      'procedureName': None,\n",
       "      'avgCharge': None},\n",
       "     'sheetCsvFile': PosixPath('processing/raw-csv/AHMC Anaheim Regional Medical Center/Price Transparency CDM.csv'),\n",
       "     'headerIdx': 2,\n",
       "     'hasValidHeaders': True,\n",
       "     'trimmedCsvPath': PosixPath('processing/trimmed-csv/AHMC Anaheim Regional Medical Center/Price Transparency CDM.csv')}},\n",
       "   'error': None})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = savePickleSafe(metadata, Path('.') / \"metadata.pickle\")\n",
    "metadata = readPickle(path)\n",
    "list(metadata.items())[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1705a9f-e5d1-4514-b7f3-4c6e066bfecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "The headers are expected to occupy one row and be complete. \n",
    "\n",
    "### Manual Change Notes\n",
    "The following hospitals had headers spanning multiple rows and were edited to use a single row:\n",
    "- Ballard Rehab\n",
    "- Childrens Hospital of Orange\n",
    "- Heritage Oaks H (also had headers interseded with the data which were removed)\n",
    "- Madera Community Hospital (also removed an empty column)\n",
    "- Vibra Rehabilitation Hospital\n",
    "\n",
    "The following hospitals had an extra, unnamed column that was named or deleted:\n",
    "- Keck Hospital of USC\n",
    "- Kindred Hospital - San Francisco Bay Area\n",
    "\n",
    "The following hospitals had bad data which were unreadable and manually unaddressable:\n",
    "- Colorado River Medicare: many header rows interseded with the data\n",
    "- Good Samaritan Hospital: Unreadable, and has only one column. \n",
    "\n",
    "\n",
    "### Interesting\n",
    "St. Joseph Hospital - Eureka has both a CPT Code and an HCPCS column which means that we can use this to relate both, potentially. This may be unlikely because CPT is supposed to be a subset of HCPCS and it is hard that a procedure may involve both codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c830a0-69be-45f7-9b17-745c4a42280e",
   "metadata": {},
   "source": [
    "### Finding the column mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823c2da-51ea-49d4-951b-ab9c4b43fa3a",
   "metadata": {},
   "source": [
    "The relevant columns are CPT Code, procedure name, and average charge. \n",
    "\n",
    "Use the sheet columns, process that list with regex and manual input to map the columns. \n",
    "\n",
    "In this step we will catch errors on files that do not contain identifiable column names or that don't have at least 2 relevant column names. \n",
    "\n",
    "Relevant procedure fields:\n",
    "- CPT Code: the standard CPT Code for the medical procedure\n",
    "- HCPCS Code: the HCPCS Code for the medical procedure\n",
    "- Avg Charge: the charge reported by the hospital for that procedure\n",
    "- Procedure description: the description of the procedure.\n",
    "\n",
    "How do I preserve data integrity? I would like cpt code and hospital id to make a primary key, but the data is messy. Furthermore many hospitals don't have a cpt code and I still want to report their procedures. \n",
    "\n",
    "I will process the data as is, including duplicates and missing CPT codes. The final clean csv will contain a standarized dataset of all hospitals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0af256f-c301-4b82-b72e-4540ce409e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [00:11<00:00, 27.00it/s]\n"
     ]
    }
   ],
   "source": [
    "structuredCsvDir = Path('.') / 'processing' / 'structured-csv'\n",
    "\n",
    "IRRELEVANT_REGEX = re.compile(r\"^.*(ProcedureID|multiplier|revenue|internal| id|statistical|type|status|comment|note|%|change|previous|#|rev | revenue|department|hsp|eap|ref|date|inpatient|i\\/p|ip | ip|pharmacy|category|chg cat|mnemonic|dept|group|revcd|rev_code|fim dp|fim cd|sim cd).*$\"\n",
    "                              , re.MULTILINE | re.IGNORECASE)\n",
    "IRRELEVANT_REGEX_2 = re.compile(r\"^(SJGH Hosp ProFee Price|SJGH CDM|Shrine CDM|cod_dtl_ext_id|cod_dtl_ds|comm|PROC \\(CDM\\)|total.charges|code|code\\.1|HOSPITAL|id|ip|rev|mclcde|s|cdm|cdm.num|ub.code|chg.code|charge.code|chargecode|servicecode|procedure.code|charge.master.code|chrg.code|tx|wgt|t|uos|year|a|FQHC|effective)$\"\n",
    "                                , re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "IRRELEVANT_REGEX_3 = re.compile(r\"^.*(chg.cod|proc.cd|compute|org|account|item.id|active|payor|lst.chg|m.caid|edit|revc|overrides|mod|pt.chg|rx|cdm.code|increase|percentage|facility|man.price|pct|site|ip/er|inpat|taxable|exception|minimum|fractional|difference|tmmc.cdm|sts|2020).*$\"\n",
    "                                , re.MULTILINE | re.IGNORECASE)\n",
    "IRRELEVANT_REGEX_4 = re.compile(r\"^(.*(service.code|proc.code|charge.*code|charge.number|proc.*code|item.number|px.code|ivnum|code |number|units|charge.*item|sta.cd|int.id).*)$\"\n",
    "                                , re.MULTILINE | re.IGNORECASE)\n",
    "EXCEPTION_REGEX = re.compile(r\"^(PT CHG \\$|REVENUE DESC|Charge Code Description|ChargeCode Description)$\"\n",
    "                             , re.MULTILINE | re.IGNORECASE)\n",
    "PRICE_REGEX = re.compile(r\"^(.*(\\$|AVG TOTAL CHARGE|price|cur.chg|average|amount|gross|amt|final.charge|rate|cost|fee).*|charge|standard.charge|hospital.charge|unit.charge|charge|.*LOCATION \\[IP\\/OP\\]|CURRENT CHARGE)$\"\n",
    "                         , re.MULTILINE | re.IGNORECASE)\n",
    "DESC_REGEX = re.compile(r\"^(.*(name|desc).*)$\"\n",
    "                        , re.MULTILINE | re.IGNORECASE)\n",
    "CPT_REGEX = re.compile(r\"^(.*(cpt).*)$\"\n",
    "                        , re.MULTILINE | re.IGNORECASE)\n",
    "HCPC_REGEX = re.compile(r\"^(.*(hcpc).*)$\"\n",
    "                        , re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "columnNamesMap = defaultdict(list)\n",
    "\n",
    "for hospital, hospitalData in tqdm(metadata.items()):\n",
    "    if not hospitalData['hasValidPaths'] or not hospitalData['hasValidSheets']:\n",
    "            continue\n",
    "    for sheet, sheetData in metadata[hospital]['sheets'].items():\n",
    "        if not hospitalData['sheets'][sheet]['hasValidHeaders']:\n",
    "            continue\n",
    "        df = pd.read_csv(sheetData['trimmedCsvPath'])\n",
    "        columnNames = df.columns\n",
    "        columnMappings = {\n",
    "            'price': [],\n",
    "            'desc': [],\n",
    "            'cpt': [],\n",
    "            'hcpc': []\n",
    "        }\n",
    "        for columnName in columnNames:\n",
    "            if (IRRELEVANT_REGEX.match(columnName)\\\n",
    "            or IRRELEVANT_REGEX_2.match(columnName)\\\n",
    "            or IRRELEVANT_REGEX_3.match(columnName)\\\n",
    "            or IRRELEVANT_REGEX_4.match(columnName))\\\n",
    "            and not EXCEPTION_REGEX.match(columnName):\n",
    "                continue\n",
    "            if PRICE_REGEX.match(columnName):\n",
    "                columnMappings['price'].append(columnName)\n",
    "                continue\n",
    "            if DESC_REGEX.match(columnName):\n",
    "                columnMappings['desc'].append(columnName)\n",
    "                continue\n",
    "            if CPT_REGEX.match(columnName):\n",
    "                columnMappings['cpt'].append(columnName)\n",
    "                continue\n",
    "            if HCPC_REGEX.match(columnName):\n",
    "                columnMappings['hcpc'].append(columnName)\n",
    "                continue\n",
    "                \n",
    "        outputDf = pd.DataFrame()\n",
    "        for key, value in columnMappings.items():\n",
    "            if len(value) <= 0:\n",
    "                continue\n",
    "            elif len(value) >1: \n",
    "                print(hospital)\n",
    "                print(columnNames.tolist())\n",
    "                print(json.dumps(columnMappings, indent=2))\n",
    "                print()\n",
    "                userInput = input()\n",
    "                if userInput == 'e':\n",
    "                    print('write the error')\n",
    "                    input()\n",
    "                continue\n",
    "            # Only 1 item in the list\n",
    "            else:\n",
    "                outputDf[key] = df[value[0]]\n",
    "        outputDf.set_index('desc', inplace=True, drop=True)\n",
    "        filepath = saveSheetToCsv(outputDf, sheet, structuredCsvDir / hospital)\n",
    "        metadata[hospital]['sheets'][sheet]['hasValidStructure']=True\n",
    "        metadata[hospital]['sheets'][sheet]['structuredCsvPath']=filepath\n",
    "        metadata[hospital]['sheets'][sheet]['columnMappings']=columnMappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565521cb-8697-447c-9749-2a6d577609f1",
   "metadata": {},
   "source": [
    "Combined multiple column header to single column:\n",
    "- BHC Freemont hospital\n",
    "- BHC Alhambra Hospital\n",
    "- ST. Agnes Medical Center (single row header had to be moved). \n",
    "\n",
    "Deleted columns:\n",
    "- Childrens Hospital at Mission: OP CHARGES, OP AVG CHARGE, CPT01, CPT02\n",
    "- Childrens Hospital of Orange County: OP CHARGES, OP AVG CHARGE\n",
    "- Mission Hospital Regional Medical Center: CMM OUTPATIENT [OP]\n",
    "- Oak Valley District Hospital: Round\n",
    "- Providence Holy Cross Medical Center: CHC LOCATION OUTPATIENT [OP]\n",
    "- Providence Little Co. of Mary Med Ctr - San Pedro: CHC LOCATION OUTPATIENT [OP]\n",
    "- Providence Little Co. of Mary Med Ctr - Torrance: CHC LOCATION OUTPATIENT [OP]\n",
    "- Providence ST. Joseph Hospital: CHC LOCATION OUTPATIENT [OP]\n",
    "- Providence St John's Health Center: CJN LOCATION OUTPATIENT [OP]\n",
    "- Providence St Joseph Medical Center: CSJ LOCATION OUTPATIENT [OP]\n",
    "- Providence Tarzana Medical Center: CTZ LOCATION OUTPATIENT [OP]\n",
    "- ST. Jude Medical Center: CFM OUTPATIENT [OP]\n",
    "- Mayers Memorial Hospital: Code detail description\n",
    "- Marin General Hospital: Price 2\n",
    "- San Joaquin General Hospital: SJGH Hosp ProFee Price\n",
    "- Kindred Hospital - Westminster: Cost\n",
    "- Northern Inyo Hospital: default cost, minimum price\n",
    "\n",
    "Removed empty column on index\n",
    "- Aurora Behavioral Healthcare - Santa Rosa\n",
    "- Aurora Charter Oak\n",
    "- Aurora Las Encinas Hospital\n",
    "- Aurora San Diego Hospital\n",
    "- Aurora Vista del Mar Hospital\n",
    "\n",
    "\n",
    "Column name typo correction:\n",
    "- Corona Regional Medical Center\n",
    "- Southwest Healthcare System - Murrieta\n",
    "- Temecula Valley Hospital\n",
    "\n",
    "Removed renamed axis in Excel for header:\n",
    "- Madera Community Hospital\n",
    "\n",
    "Renamed columns:\n",
    "- UCSD Medical Center: Default -> price\n",
    "- Unversity of California Irvine Medical Center: OP -> price\n",
    "- ST. Rose Hospital: procedure -> procedureId\n",
    "- Mayers Memorial Hospital: Charge -> price\n",
    "- College Medical Center: CHARGE_ITEM => CHARGE_DESC\n",
    "- Marina Del Rey Hospital: Charge_code -> Id\n",
    "- Regional Medical Center of San Jose: I/PCharge -> Price\n",
    "- Eastern Plumas Health Care: Procedure Code -> HCPC code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f5aa6-0934-48bd-a4b5-33db57c9f023",
   "metadata": {},
   "source": [
    "### Parsing the files\n",
    "\n",
    "The final step before loading is to extract the data from the records of the csv files. We will also apply non-contextual transformations i.e. transformations that are non opinionated before loading this to our data warehouse. \n",
    "\n",
    "- If HCPC has value and CPT doesn't, use HCPC value\n",
    "- Replace CPT code by their match to a 5 digit regex surrounded by 0 or more non digits. Convert to number\n",
    "- Replace all space characters with spaces on procedures, strip whitespaces\n",
    "- Convert price to number, multiply by 100, look for negatives and anomalies. \n",
    "- Drop NA for desc and price fields\n",
    "- Report row count per hospital and validate anomalies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49aeb6bd-c4b8-4bec-afe8-7ba1fd4c4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNaWithColumn(df, consumer, provider):\n",
    "    mask = df[consumer].isna() | df[consumer].isnull()\n",
    "    mask = mask & ~ (df[provider].isna() | df[provider].isnull())\n",
    "    df[consumer].mask(mask, df[provider], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc5383a-9863-45f2-a8e4-20c2a497184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanColumnWhitespace(column):\n",
    "    column = column.str.strip('\"')\n",
    "    column = column.str.strip(\"'\")\n",
    "    column = column.str.strip()\n",
    "    column = column.str.replace(r'\\s+', ' ', regex=True)\n",
    "    column[column==' '] = pd.NA\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3049c31f-74a6-4a50-876a-6127b93a87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSheet(df):\n",
    "    # print(f'{hospital}:')\n",
    "    # print(f\"Initial rows: {len(df)}\")\n",
    "\n",
    "    # clean whitespace, clean NAs        \n",
    "    df['desc'] = cleanColumnWhitespace(df['desc'].astype(str))\n",
    "    mask = (df['desc']==' ') | (df['desc']=='') | (df['desc'].str.lower() == 'nan') \\\n",
    "        | (df['desc'].str.lower() == 'do not use')\n",
    "    df['desc'].mask(mask, pd.NA, inplace=True)\n",
    "    prev = len(df)\n",
    "    df.dropna(axis=0, subset='desc', inplace=True)\n",
    "    curr = len(df)\n",
    "    # print(f\"Desc NA: {prev-curr}\")\n",
    "    prev=len(df)\n",
    "    df.drop_duplicates(subset='desc', inplace=True, keep='last')\n",
    "    curr=len(df)\n",
    "    # print(f\"Desc Dup: {prev-curr}\")\n",
    "\n",
    "    df['price'] = cleanColumnWhitespace(df['price'].astype(str))\n",
    "    df['price'].mask((df['price']==' ' )| df['price']=='', pd.NA, inplace=True)\n",
    "    prev = len(df)\n",
    "    df.dropna(axis=0, subset='price', inplace=True)\n",
    "    curr = len(df)\n",
    "    # print(f\"Price NA: {prev-curr}\")\n",
    "\n",
    "    # convert type to num, multiply price by 100\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    prev=len(df)\n",
    "    df.dropna(axis=0, subset='price', inplace=True)\n",
    "    curr = len(df)\n",
    "    # print(f\"Price non-numeric: {prev-curr}\")\n",
    "    df['price'] = (df['price'] * 100).astype(np.int64)\n",
    "\n",
    "    if 'cpt' in df.columns:\n",
    "        df['cpt'] = cleanColumnWhitespace(df['cpt'].astype(str))\n",
    "\n",
    "    if 'hcpc' in df.columns:\n",
    "        df['hcpc'] = cleanColumnWhitespace(df['hcpc'].astype(str))\n",
    "\n",
    "    # leverage hcpc data if any\n",
    "    if 'hcpc' in df.columns:\n",
    "        if 'cpt' not in df.columns:\n",
    "            df['cpt'] = df['hcpc']\n",
    "        else:\n",
    "            df = fillNaWithColumn(df, 'cpt', 'hcpc')\n",
    "        df.drop('hcpc', axis=1, inplace=True)\n",
    "\n",
    "    # parse cpt codes \n",
    "    if 'cpt' in df.columns:\n",
    "        if hospital == 'Los Robles Medical Center':\n",
    "            df['cpt'] = df['cpt'].str.slice(start=1)\n",
    "\n",
    "        df['cpt'] = df['cpt'].astype(str)\n",
    "        df['cpt'] = cleanColumnWhitespace(df['cpt']) \n",
    "        mask = ~df['cpt'].str.match(CPT_REGEX)\n",
    "        df['cpt'].mask(mask, pd.NA, inplace=True)\n",
    "        df['cpt'] = df['cpt'].str.replace(CPT_REGEX, r\"\\1\", regex=True)\n",
    "\n",
    "        # Drop duplicates\n",
    "        mask = df.duplicated(subset='cpt', keep='last')\n",
    "        mask &= df['cpt'].notnull()\n",
    "        prev = len(df)\n",
    "        # display(df)\n",
    "        df=df.loc[~mask]\n",
    "        curr = len(df)\n",
    "        # print(f\"CPT Dup: {prev-curr}\")\n",
    "    # print(f\"Remaining {len(df)}\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44aba710-217f-4b80-8ef8-19ea07ab1e50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [00:41<00:00,  7.69it/s]\n"
     ]
    }
   ],
   "source": [
    "CPT_REGEX = re.compile(r\"^(\\d{5})([\\- ,]?([^\\n]{2})?)*$\")\n",
    "parsedCsvDir = Path('.') / 'processing' / 'parsed-csv'\n",
    "lowDataHospitals = []\n",
    "\n",
    "for hospital, hospitalData in tqdm(sorted(metadata.items())):\n",
    "    if not hospitalData[\"hasValidPaths\"] or not hospitalData[\"hasValidSheets\"]:\n",
    "        continue\n",
    "    for sheet, sheetData in hospitalData[\"sheets\"].items():\n",
    "        if not sheetData[\"hasValidHeaders\"] or not sheetData[\"hasValidStructure\"]:\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(sheetData['structuredCsvPath'])\n",
    "        df = parseSheet(df)\n",
    "            \n",
    "        if len(df) < 100:\n",
    "            lowDataHospitals.append((hospital, len(df)))\n",
    "            \n",
    "        df.set_index('desc', inplace=True)\n",
    "        resultPath = saveSheetToCsv(df, sheet, parsedCsvDir / hospital)\n",
    "        metadata[hospital]['sheets'][sheet]['parsedCsvPath'] = resultPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4eaeb-386a-4679-951a-a0ac5c5ede42",
   "metadata": {},
   "source": [
    "### Hospitals with low data\n",
    "['Aurora Behavioral Healthcare - Santa Rosa',\n",
    " 'Aurora Charter Oak',\n",
    " 'Aurora Las Encinas Hospital',\n",
    " 'Aurora San Diego Hospital',\n",
    " 'Aurora Vista del Mar Hospital',\n",
    " 'BHC Alhambra Hospital',\n",
    " 'BHC Fremont Hospital',\n",
    " 'Bakersfield Behavioral Healthcare Hospital',\n",
    " 'Eastern Plumas Health Care',\n",
    " 'Heritage Oaks Hospital',\n",
    " 'Kindred Hospital - Ontario',\n",
    " 'L.A. Co. - Harbor-UCLA Medical Center',\n",
    " 'L.A. Co. - Olive View Medical Center',\n",
    " 'L.A. Co. - Rancho Los Amigos Hospital',\n",
    " 'L.A. Co. - USC Medical Center',\n",
    " 'Sierra Vista Hospital']\n",
    " \n",
    "I have obtained low amounts of data from these hospitals (<100 procedures)\n",
    "- Eastern Plumas Health Care does not report procedure name hence I can't extract data. \n",
    "- Kindred Hospital - Ontario contains mostly duplicate names\n",
    "- Other hospitals did not report many procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46244cfd-4928-4fc4-9fcb-cfd022b4282a",
   "metadata": {},
   "source": [
    "### Enrich CPT Codes for similar descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c53fa4e7-785b-4fd1-ab8a-bb2e31832299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [00:12<00:00, 26.52it/s]\n"
     ]
    }
   ],
   "source": [
    "descToCptMap = dict()\n",
    "descCount = Counter()\n",
    "cptCount = Counter()\n",
    "\n",
    "totalRecords = 0\n",
    "cptRecords = 0\n",
    "inferredCptRecords = 0\n",
    "\n",
    "for hospitalName, hospitalData in tqdm(metadata.items()):\n",
    "    if 'sheets' not in hospitalData:\n",
    "        continue\n",
    "    for sheetName, sheetData in hospitalData['sheets'].items():\n",
    "        if 'parsedCsvPath' not in sheetData:\n",
    "            continue\n",
    "        df = pd.read_csv(sheetData['parsedCsvPath'], dtype={'desc': str, 'price': int, 'cpt': str})\n",
    "        df['desc'] = df['desc'].astype(str)\n",
    "        if 'cpt' not in df.columns:\n",
    "            continue\n",
    "        totalRecords += len(df)\n",
    "        df = df[df['cpt'].notnull()]\n",
    "        cptRecords += len(df)\n",
    "        for idx, row in df.iterrows():\n",
    "            descName = row['desc'].lower()\n",
    "            descToCptMap[descName] = row['cpt']\n",
    "            descCount[descName] += 1\n",
    "            if 'cpt' in df.columns:\n",
    "                cptCode = int(row['cpt']) if not row['cpt'] == '' else -1\n",
    "                cptCount[cptCode]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "392f22bd-18df-4f3a-8b6a-48554fb33770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [02:12<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for hospitalName, hospitalData in tqdm(metadata.items()):\n",
    "    if 'sheets' not in hospitalData:\n",
    "        continue\n",
    "    for sheetName, sheetData in hospitalData['sheets'].items():\n",
    "        if 'parsedCsvPath' not in sheetData:\n",
    "            continue\n",
    "        df = pd.read_csv(sheetData['parsedCsvPath'], dtype={'desc': str, 'price': int, 'cpt': str})\n",
    "        df['desc'] = df['desc'].astype(str)\n",
    "        if 'cpt' not in df.columns:\n",
    "            df['cpt'] = pd.NA\n",
    "        mask = df['cpt'].isnull()\n",
    "\n",
    "        for idx, row in df[mask].iterrows():\n",
    "            descName = row['desc'].lower()\n",
    "            if descName in descToCptMap and descToCptMap[descName] != -1:\n",
    "                inferredCptRecords += 1\n",
    "                cptCode = descToCptMap[descName]\n",
    "                df.loc[idx, 'cpt']=cptCode\n",
    "        \n",
    "        df['hospital'] = hospitalName\n",
    "        df.set_index('hospital', inplace=True)   \n",
    "        df=df[['cpt','desc','price']]\n",
    "        saveSheetToCsv(df, sheetName, parsedCsvDir / hospitalName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c039cbba-3c40-471c-bbd0-abd7405d1e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855039, 135686, 84197)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalRecords, cptRecords, inferredCptRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef87840d-b967-424e-bfbe-4bfabc21643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "didReportCptCount = 0\n",
    "for hospital, hospitalData in metadata.items():\n",
    "    if not 'sheets' in hospitalData:\n",
    "        continue\n",
    "    for sheet, sheetData in hospitalData['sheets'].items():\n",
    "        if not 'columnMappings' in sheetData or not 'cpt' in sheetData['columnMappings']:\n",
    "            continue\n",
    "        if len(sheetData['columnMappings']['cpt']) > 0 or len(sheetData['columnMappings']['hcpc']) > 0:\n",
    "            didReportCptCount += 1\n",
    "            continue\n",
    "didReportCptCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1c11a-26f6-449e-9f71-c8f2355fa0a5",
   "metadata": {},
   "source": [
    "### Some final stats\n",
    "In total 80 hospitals reported CPT or HCPC codes related to procedures. \n",
    "There are 855039 total records reported, where 135686 have a CPT code and 84197 had clear enough names that CPT Code could be inferred from other hospitals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb516cbb-bf0a-41d7-8842-8670be819ba6",
   "metadata": {},
   "source": [
    "### Prepare database input\n",
    "\n",
    "Prepare input with only the rows that have an assigned CPT Code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fbb029b-d5c8-4ee9-8594-054e0099fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 321/321 [00:06<00:00, 47.61it/s]\n"
     ]
    }
   ],
   "source": [
    "databaseInputDir = Path('processing') / 'database-input'\n",
    "\n",
    "for hospital, hospitalData in tqdm(metadata.items()):\n",
    "    if not 'sheets' in hospitalData:\n",
    "        continue\n",
    "    for sheet, sheetData in hospitalData['sheets'].items():\n",
    "        if 'parsedCsvPath' not in sheetData:\n",
    "            continue\n",
    "        df = pd.read_csv(sheetData['parsedCsvPath'], \n",
    "                         dtype=dict(hospital=str, cpt=str, desc=str, price=int))\n",
    "        if 'cpt' not in df.columns:\n",
    "            continue\n",
    "        df.dropna(axis=0, subset=['cpt'], inplace=True)\n",
    "        df.set_index('hospital', inplace=True)\n",
    "        saveSheetToCsv(df, sheet, databaseInputDir / hospital)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
